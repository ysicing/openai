# OpenAI Go SDK

[![Go Report Card](https://goreportcard.com/badge/github.com/ysicing/openai)](https://goreportcard.com/report/github.com/ysicing/openai)
[![Test Coverage](https://img.shields.io/badge/coverage-71.2%25-brightgreen)](https://github.com/ysicing/openai)
[![Go Version](https://img.shields.io/badge/go-1.24-blue)](https://golang.org/dl/)

A **flexible and secure** Go SDK for OpenAI and OpenAI-compatible APIs including **local models** like **Ollama**.

## âœ¨ Features

- ğŸ”Œ **Multi-Provider Support**: OpenAI, Azure OpenAI, DeepSeek, ZhiPu, **Ollama**, and any OpenAI-compatible API
- ğŸ›¡ï¸ **Security First**: Comprehensive validation, TLS warnings, safe error handling
- ğŸ§ª **Well-Tested**: 71.2% test coverage with comprehensive unit tests
- ğŸš€ **Developer-Friendly**: Clean functional options pattern, extensive documentation
- âš¡ **Performant**: Optimized HTTP client, connection pooling, context-aware
- ğŸ”§ **Flexible**: Support for custom BaseURL, proxies, timeouts, and all OpenAI parameters

## ğŸ“¦ Installation

```bash
go get github.com/ysicing/openai
```

## ğŸš€ Quick Start

### OpenAI
```go
package main

import (
    "context"
    "log"
    "os"

    "github.com/ysicing/openai/openai"
)

func main() {
    client, err := openai.New(
        openai.WithToken(os.Getenv("OPENAI_API_KEY")),
        openai.WithModel(openai.GPT4oMini),
    )
    if err != nil {
        log.Fatal(err)
    }

    resp, err := client.Completion(
        context.Background(),
        "You are a helpful assistant.",
        "Explain quantum computing in simple terms",
    )
    if err != nil {
        log.Fatal(err)
    }

    log.Println(resp.Content)
}
```

### Ollama (Local AI)
```go
client, err := openai.New(
    openai.WithToken("ollama"),
    openai.WithProvider(openai.Ollama),  // è‡ªåŠ¨é…ç½® localhost:11434
    openai.WithModel("llama3.1:latest"),
    openai.WithTimeout(300),  // æœ¬åœ°æ¨¡å‹éœ€è¦æ›´é•¿è¶…æ—¶
)
```

### DeepSeek (OpenAI-Compatible)
```go
client, err := openai.New(
    openai.WithToken(os.Getenv("DEEPSEEK_API_KEY")),
    openai.WithBaseURL("https://api.deepseek.com/v1"),
    openai.WithModel(openai.DeepseekChat),
)
```

## ğŸ”§ Configuration Options

| Option | Description | Example |
|--------|-------------|---------|
| `WithToken` | API authentication token | `"sk-..."` |
| `WithModel` | Model name | `"gpt-4o-mini"` |
| `WithProvider` | Service provider | `openai.Ollama` |
| `WithBaseURL` | Custom API endpoint | `"http://localhost:11434/v1"` |
| `WithMaxTokens` | Maximum output tokens | `2000` |
| `WithTemperature` | Response creativity (0-2) | `0.7` |
| `WithTopP` | Nucleus sampling | `0.9` |
| `WithTimeout` | Request timeout | `60 * time.Second` |
| `WithProxyURL` | HTTP proxy | `"http://proxy:8080"` |
| `WithSocksURL` | SOCKS5 proxy | `"socks5://proxy:1080"` |
| `WithSkipVerify` | Skip TLS verification | `true` âš ï¸ |

## ğŸ“š Supported Providers

### Built-in Providers (Special Configuration)

| Provider | Official Support | Default URL | Notes |
|----------|-----------------|-------------|-------|
| OpenAI | âœ… | `https://api.openai.com/v1` | Default provider |
| Azure OpenAI | âœ… | Azure endpoint | Enterprise features |
| **Ollama** | âœ… | `http://localhost:11434/v1` | **Local models** |

âœ… = Built-in provider with special configuration

### OpenAI-Compatible Providers (Via WithBaseURL)

All other providers use the **default OpenAI-compatible mode**. Just specify the endpoint:

```go
// DeepSeek
openai.WithBaseURL("https://api.deepseek.com/v1")

// ZhiPu (æ™ºè°±)
openai.WithBaseURL("https://open.bigmodel.cn/api/paas/v4/")

// LM Studio, LocalAI, vLLM, etc.
openai.WithBaseURL("http://localhost:1234/v1")
```

**Compatible with any OpenAI-compatible service:**
- DeepSeek, ZhiPu, Moonshot, Kimi, Qwen, etc. (Chinese providers)
- LM Studio, LocalAI, vLLM (Self-hosted)
- Any other service with OpenAI-compatible API

## ğŸ’¡ Design Philosophy

We use a **simplified approach**:
- âœ… Only OpenAI, Azure, and Ollama have **special configurations**
- âœ… All other providers use **default OpenAI-compatible mode**
- âœ… Just use `WithBaseURL` to specify the endpoint

This design makes the code simpler and supports more services!

## ğŸ¯ Advanced Usage

### Multi-turn Conversations
```go
messages := []openai.ChatCompletionMessage{
    {Role: openai.ChatMessageRoleUser, Content: "Hello!"},
}

resp, err := client.CreateChatCompletionWithMessage(context.Background(), messages)
if err != nil {
    log.Fatal(err)
}

messages = append(messages, resp.Choices[0].Message)
messages = append(messages, openai.ChatCompletionMessage{
    Role: openai.ChatMessageRoleUser,
    Content: "What is your name?",
})

resp2, err := client.CreateChatCompletionWithMessage(context.Background(), messages)
```

### Image Understanding (GPT-4V)
```go
resp, err := client.ImageCompletion(
    context.Background(),
    "https://example.com/image.jpg",
    "You are a helpful assistant.",
    "Describe this image in detail",
)
```

### Custom Headers
```go
client, err := openai.New(
    openai.WithToken("api-key"),
    openai.WithHeaders([]string{
        "X-Custom-Header=custom-value",
        "Authorization=Bearer token",
    }),
)
```

## ğŸ›¡ï¸ Security Features

- âœ… **Response Validation**: Prevents panics on malformed API responses
- âœ… **TLS Warnings**: Clear documentation about security implications of `WithSkipVerify`
- âœ… **Safe Error Handling**: No credential leakage in error messages
- âœ… **Input Validation**: Robust header parsing with `SplitN`
- âœ… **Proxy Security**: Support for both HTTP and SOCKS5 proxies

## ğŸ§ª Testing

Run all tests:
```bash
go test ./... -v
```

With coverage report:
```bash
go test ./... -cover
```

Test results:
```
PASS
coverage: 71.2% of statements
ok      github.com/ysicing/openai/openai    0.496s
```

## ğŸ“– Examples

See the `example/` directory for complete working examples:
- `example/deepseek/` - DeepSeek API usage
- `example/zhipu/` - ZhiPu API usage
- `example/ollama/` - Local Ollama usage

```bash
# Run DeepSeek example
cd example/deepseek
DEEPSEEK_API_KEY=your_key go run main.go

# Run Ollama example (requires Ollama running)
cd example/ollama
ollama run llama3.1:latest
go run main.go
```

## ğŸ¤ Contributing

Contributions are welcome! Please feel free to submit a Pull Request.

## ğŸ“„ License

MIT License - see LICENSE file for details.

## ğŸ™ Acknowledgments

- [sashabaranov/go-openai](https://github.com/sashabaranov/go-openai) - OpenAI Go library
- [Ollama](https://ollama.ai) - Local AI models
- All contributors and users of this SDK
